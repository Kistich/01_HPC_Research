#!/usr/bin/env python3
"""
ç¨³å®šç‰ˆå…¨é‡æ•°æ®å¤„ç†è„šæœ¬
ä¿®å¤äº†æ‰€æœ‰å·²çŸ¥é—®é¢˜ï¼š
1. å­—ç¬¦ä¸²æ‹¼æ¥é”™è¯¯
2. tqdmå…¼å®¹æ€§é—®é¢˜  
3. ä¸­é—´æ–‡ä»¶ä¿å­˜å’Œæ–­ç‚¹ç»­ä¼ 
4. è¿›ç¨‹ç®¡ç†ä¼˜åŒ–
"""

import os
import sys
import time
import logging
import signal
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path

# æ·»åŠ æ¨¡å—è·¯å¾„
sys.path.append(str(Path(__file__).parent))

# é…ç½®æ—¥å¿—
log_filename = f"stable_processing_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(log_filename, encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# å…¨å±€å˜é‡ç”¨äºä¼˜é›…é€€å‡º
processing_interrupted = False

def signal_handler(signum, frame):
    """æ”¹è¿›çš„ä¿¡å·å¤„ç†å™¨"""
    global processing_interrupted
    processing_interrupted = True
    logger.warning(f"æ¥æ”¶åˆ°ä¿¡å· {signum}ï¼Œè®¾ç½®ä¸­æ–­æ ‡å¿—...")
    # ä¸ç«‹å³é€€å‡ºï¼Œè®©ä¸»ç¨‹åºæ£€æŸ¥æ ‡å¿—åä¼˜é›…é€€å‡º

def check_interrupt():
    """æ£€æŸ¥æ˜¯å¦éœ€è¦ä¸­æ–­å¤„ç†"""
    if processing_interrupted:
        logger.info("æ£€æµ‹åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨ä¼˜é›…é€€å‡º...")
        sys.exit(0)

def estimate_processing_time(input_file: str) -> tuple:
    """ä¼°ç®—å¤„ç†æ—¶é—´å’Œè¾“å‡ºè§„æ¨¡"""
    logger.info("æ­£åœ¨åˆ†æè¾“å…¥æ–‡ä»¶...")
    line_count = int(os.popen(f"wc -l {input_file}").read().split()[0]) - 1
    
    # åŸºäºä¼˜åŒ–åçš„æ€§èƒ½ä¼°ç®—
    processing_speed = 2000  # æ¡è®°å½•/ç§’ (ä¼˜åŒ–å)
    retention_rate = 0.977
    
    estimated_time_seconds = line_count / processing_speed
    estimated_output_records = int(line_count * retention_rate)
    
    return line_count, estimated_time_seconds, estimated_output_records

def format_time(seconds: float) -> str:
    """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
    if seconds < 60:
        return f"{seconds:.1f}ç§’"
    elif seconds < 3600:
        return f"{seconds/60:.1f}åˆ†é’Ÿ"
    else:
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        return f"{hours}å°æ—¶{minutes}åˆ†é’Ÿ"

def check_intermediate_files():
    """æ£€æŸ¥ä¸­é—´æ–‡ä»¶çŠ¶æ€"""
    # ä½¿ç”¨ç»å¯¹è·¯å¾„ï¼ŒåŸºäºè„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = Path(__file__).parent

    files_to_check = {
        "è„šæœ¬ç‰¹å¾åˆ†æ": script_dir / "full_processing_outputs/stage1_generation_filter/analyzed_features.csv",
        "äºŒæœŸé«˜ç½®ä¿¡åº¦æ•°æ®": script_dir / "full_processing_outputs/stage1_generation_filter/second_generation_high.csv",
        "æ—¶é—´å¤„ç†ç»“æœ": script_dir / "full_processing_outputs/stage2_time_processing/time_processed_clean.csv",
        "ç”¨æˆ·æ¨æ–­ç»“æœ": script_dir / "full_processing_outputs/stage3_user_inference/user_inference_complete.csv",
        "ç¼ºå¤±åˆ†æç»“æœ": script_dir / "full_processing_outputs/stage4_missing_analysis/comprehensive_missing_analysis_report.txt",
        "æœ€ç»ˆé‡‡æ ·ç»“æœ": script_dir / "full_processing_outputs/stage5_intelligent_sampling/intelligent_sampling_result.csv"
    }

    existing_files = {}
    for name, path in files_to_check.items():
        if path.exists():
            size_mb = path.stat().st_size / (1024 * 1024)
            try:
                if str(path).endswith('.csv'):
                    line_count = int(os.popen(f"wc -l {path}").read().split()[0]) - 1
                    existing_files[name] = {"path": str(path), "size_mb": size_mb, "records": line_count}
                    logger.info(f"âœ… {name}: {line_count:,} æ¡è®°å½• ({size_mb:.1f} MB)")
                else:
                    existing_files[name] = {"path": str(path), "size_mb": size_mb, "records": "æŠ¥å‘Šæ–‡ä»¶"}
                    logger.info(f"âœ… {name}: æŠ¥å‘Šæ–‡ä»¶ ({size_mb:.1f} MB)")
            except:
                existing_files[name] = {"path": str(path), "size_mb": size_mb, "records": "æœªçŸ¥"}
                logger.info(f"âœ… {name}: {size_mb:.1f} MB")

    return existing_files

def determine_start_stage(existing_files):
    """æ ¹æ®ç°æœ‰æ–‡ä»¶ç¡®å®šå¼€å§‹é˜¶æ®µ"""
    stage_files = {
        1: "äºŒæœŸé«˜ç½®ä¿¡åº¦æ•°æ®",
        2: "æ—¶é—´å¤„ç†ç»“æœ",
        3: "ç”¨æˆ·æ¨æ–­ç»“æœ",
        4: "ç¼ºå¤±åˆ†æç»“æœ",
        5: "æœ€ç»ˆé‡‡æ ·ç»“æœ"
    }

    # ä»æœ€é«˜é˜¶æ®µå¼€å§‹æ£€æŸ¥
    for stage in range(5, 0, -1):
        if stage_files[stage] in existing_files:
            if stage == 5:
                logger.info("ğŸ‰ æ‰€æœ‰é˜¶æ®µéƒ½å·²å®Œæˆï¼")
                return 6  # è¡¨ç¤ºå…¨éƒ¨å®Œæˆ
            else:
                logger.info(f"ğŸ“‹ å‘ç°é˜¶æ®µ{stage}è¾“å‡ºæ–‡ä»¶ï¼Œå°†ä»é˜¶æ®µ{stage+1}å¼€å§‹")
                return stage + 1

    logger.info("ğŸ“‹ æœªå‘ç°å®Œæ•´çš„é˜¶æ®µè¾“å‡ºæ–‡ä»¶ï¼Œå°†ä»é˜¶æ®µ1å¼€å§‹")
    return 1

def run_stages_from(start_stage: int, input_file: str, output_dir: str, existing_files: dict) -> str:
    """ä»æŒ‡å®šé˜¶æ®µå¼€å§‹è¿è¡Œå¤„ç†æµç¨‹"""

    # æ ¹æ®å¼€å§‹é˜¶æ®µç¡®å®šè¾“å…¥æ–‡ä»¶
    if start_stage == 1:
        stage1_output = run_stage1_with_checkpoint(input_file, output_dir)
        if not stage1_output:
            logger.error("âŒ é˜¶æ®µ1æœªäº§ç”ŸäºŒæœŸé«˜ç½®ä¿¡åº¦æ•°æ®")
            sys.exit(1)
        current_output = stage1_output
        current_stage = 2
    elif start_stage == 2:
        current_output = existing_files["äºŒæœŸé«˜ç½®ä¿¡åº¦æ•°æ®"]["path"]
        current_stage = 2
    elif start_stage == 3:
        current_output = existing_files["æ—¶é—´å¤„ç†ç»“æœ"]["path"]
        current_stage = 3
    elif start_stage == 4:
        current_output = existing_files["ç”¨æˆ·æ¨æ–­ç»“æœ"]["path"]
        current_stage = 4
    elif start_stage == 5:
        current_output = existing_files["ç”¨æˆ·æ¨æ–­ç»“æœ"]["path"]  # é˜¶æ®µ5ä½¿ç”¨é˜¶æ®µ3çš„è¾“å‡º
        current_stage = 5
    else:
        logger.error(f"âŒ æ— æ•ˆçš„å¼€å§‹é˜¶æ®µ: {start_stage}")
        sys.exit(1)

    # è¿è¡Œå‰©ä½™é˜¶æ®µ
    return run_remaining_stages_from(current_output, output_dir, current_stage)

def run_remaining_stages_from(input_data: str, output_dir: str, start_stage: int) -> str:
    """ä»æŒ‡å®šé˜¶æ®µå¼€å§‹è¿è¡Œå‰©ä½™é˜¶æ®µ"""
    current_output = input_data

    # é˜¶æ®µ2: æ—¶é—´å­—æ®µå¤„ç†
    if start_stage <= 2:
        logger.info("=" * 60)
        logger.info("é˜¶æ®µ2: æ—¶é—´å­—æ®µå¤„ç†")
        logger.info("=" * 60)
        check_interrupt()

        from modules.time_processor import TimeProcessor
        stage2_start = time.time()
        time_processor = TimeProcessor("config/time_processor_config.yaml")
        stage2_result = time_processor.process_time_fields(current_output, f"{output_dir}/stage2_time_processing")
        stage2_time = time.time() - stage2_start
        logger.info(f"é˜¶æ®µ2å®Œæˆï¼Œè€—æ—¶: {format_time(stage2_time)}")

        current_output = stage2_result.get('clean_data', stage2_result.get('processed_data', ''))
        if not current_output:
            logger.error("âŒ é˜¶æ®µ2æœªäº§ç”Ÿæœ‰æ•ˆè¾“å‡ºæ–‡ä»¶")
            return None

    # é˜¶æ®µ3: ç”¨æˆ·IDæ¨æ–­
    if start_stage <= 3:
        logger.info("=" * 60)
        logger.info("é˜¶æ®µ3: ç”¨æˆ·IDæ¨æ–­")
        logger.info("=" * 60)
        check_interrupt()

        from modules.user_inferrer import UserInferrer
        stage3_start = time.time()
        user_inferrer = UserInferrer("config/user_inference_config.yaml")
        stage3_result = user_inferrer.infer_user_ids(current_output, f"{output_dir}/stage3_user_inference")
        stage3_time = time.time() - stage3_start
        logger.info(f"é˜¶æ®µ3å®Œæˆï¼Œè€—æ—¶: {format_time(stage3_time)}")

        current_output = stage3_result.get('complete_data', '')
        if not current_output:
            logger.error("âŒ é˜¶æ®µ3æœªäº§ç”Ÿæœ‰æ•ˆè¾“å‡ºæ–‡ä»¶")
            return None

    # é˜¶æ®µ4: ç¼ºå¤±æ•°æ®åˆ†æ (çº¯åˆ†æé˜¶æ®µï¼Œä¸ä¿®æ”¹ä¸»æ•°æ®æµ)
    if start_stage <= 4:
        logger.info("=" * 60)
        logger.info("é˜¶æ®µ4: ç¼ºå¤±æ•°æ®åˆ†æ")
        logger.info("=" * 60)
        check_interrupt()

        from modules.missing_analyzer import MissingAnalyzer
        stage4_start = time.time()
        missing_analyzer = MissingAnalyzer("config/missing_analysis_config.yaml")
        stage4_reports = missing_analyzer.analyze_missing_data(current_output, f"{output_dir}/stage4_missing_analysis")
        stage4_time = time.time() - stage4_start
        logger.info(f"é˜¶æ®µ4å®Œæˆï¼Œè€—æ—¶: {format_time(stage4_time)}")

        # é˜¶æ®µ4åªç”Ÿæˆåˆ†ææŠ¥å‘Šï¼Œä¸»æ•°æ®æµç»§ç»­ä½¿ç”¨current_output
        logger.info(f"âœ… ç¼ºå¤±æ•°æ®åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {len(stage4_reports)} ä¸ªæ–‡ä»¶")
        logger.info(f"ğŸ“Š ä¸»æ•°æ®æµç»§ç»­ä½¿ç”¨: {current_output}")

    # é˜¶æ®µ5: æ™ºèƒ½é‡‡æ · (ä½¿ç”¨é˜¶æ®µ3çš„è¾“å‡º)
    if start_stage <= 5:
        logger.info("=" * 60)
        logger.info("é˜¶æ®µ5: æ™ºèƒ½é‡‡æ ·")
        logger.info("=" * 60)
        check_interrupt()

        from modules.intelligent_sampler import IntelligentSampler
        stage5_start = time.time()
        intelligent_sampler = IntelligentSampler("config/intelligent_sampling_config.yaml")
        # ä¿®æ­£: ä½¿ç”¨current_outputä½œä¸ºè¾“å…¥ï¼Œè€Œä¸æ˜¯stage4_output
        stage5_result = intelligent_sampler.perform_intelligent_sampling(current_output, f"{output_dir}/stage5_intelligent_sampling")
        stage5_time = time.time() - stage5_start
        logger.info(f"é˜¶æ®µ5å®Œæˆï¼Œè€—æ—¶: {format_time(stage5_time)}")

        # è·å–é˜¶æ®µ5è¾“å‡ºæ–‡ä»¶
        current_output = stage5_result.get('sampled_data', stage5_result.get('final_data', ''))

        # é˜¶æ®µ6: æ•°æ®æ ‡å‡†åŒ–
        logger.info("=" * 60)
        logger.info("é˜¶æ®µ6: æ•°æ®æ ‡å‡†åŒ–")
        logger.info("=" * 60)
        check_interrupt()

        from modules.data_standardizer import DataStandardizer
        stage6_start = time.time()
        data_standardizer = DataStandardizer("config/generation_filter_config.yaml")
        stage6_result = data_standardizer.standardize_data(current_output, f"{output_dir}/stage6_data_standardization")
        stage6_time = time.time() - stage6_start
        logger.info(f"é˜¶æ®µ6å®Œæˆï¼Œè€—æ—¶: {format_time(stage6_time)}")

        # è·å–æœ€ç»ˆè¾“å‡ºæ–‡ä»¶
        final_output = stage6_result['standardized_data']
        return final_output

    return current_output

def run_stage1_with_checkpoint(input_file: str, output_dir: str):
    """è¿è¡Œé˜¶æ®µ1å¹¶æ”¯æŒæ–­ç‚¹ç»­ä¼ """
    from modules.generation_filter import GenerationFilter
    
    logger.info("=" * 60)
    logger.info("é˜¶æ®µ1: ä¸€æœŸäºŒæœŸæ•°æ®è¿‡æ»¤ (æ”¯æŒæ–­ç‚¹ç»­ä¼ )")
    logger.info("=" * 60)
    
    # åˆå§‹åŒ–è¿‡æ»¤å™¨
    filter_module = GenerationFilter("config/generation_filter_config.yaml")
    
    # æ‰§è¡Œè¿‡æ»¤ (å†…éƒ¨ä¼šæ£€æŸ¥ä¸­é—´æ–‡ä»¶)
    stage1_start = time.time()
    stage1_result = filter_module.filter_data(input_file, f"{output_dir}/stage1_generation_filter")
    stage1_time = time.time() - stage1_start

    logger.info(f"é˜¶æ®µ1å®Œæˆï¼Œè€—æ—¶: {format_time(stage1_time)}")

    # è·å–é˜¶æ®µ1çš„ä¸»è¦è¾“å‡ºæ–‡ä»¶ (é«˜ç½®ä¿¡åº¦äºŒæœŸæ•°æ®)
    stage1_output = stage1_result.get('second_generation_high', '')
    if not stage1_output:
        logger.error("âŒ é˜¶æ®µ1æœªäº§ç”Ÿæœ‰æ•ˆçš„äºŒæœŸé«˜ç½®ä¿¡åº¦æ•°æ®")
        return None

    return stage1_output

def run_remaining_stages(stage1_output: str, output_dir: str):
    """è¿è¡Œå‰©ä½™é˜¶æ®µ"""
    from modules.time_processor import TimeProcessor
    from modules.user_inferrer import UserInferrer
    from modules.missing_analyzer import MissingAnalyzer
    from modules.intelligent_sampler import IntelligentSampler
    from modules.data_standardizer import DataStandardizer
    
    current_input = stage1_output
    
    # é˜¶æ®µ2: æ—¶é—´å¤„ç†
    logger.info("=" * 60)
    logger.info("é˜¶æ®µ2: æ—¶é—´å­—æ®µå¤„ç†")
    logger.info("=" * 60)
    check_interrupt()
    
    stage2_start = time.time()
    time_processor = TimeProcessor("config/time_processor_config.yaml")
    stage2_result = time_processor.process_time_fields(current_input, f"{output_dir}/stage2_time_processing")
    stage2_time = time.time() - stage2_start
    logger.info(f"é˜¶æ®µ2å®Œæˆï¼Œè€—æ—¶: {format_time(stage2_time)}")

    # è·å–é˜¶æ®µ2çš„ä¸»è¦è¾“å‡ºæ–‡ä»¶
    stage2_output = stage2_result.get('clean_data', stage2_result.get('processed_data', ''))
    if not stage2_output:
        logger.error("âŒ é˜¶æ®µ2æœªäº§ç”Ÿæœ‰æ•ˆè¾“å‡ºæ–‡ä»¶")
        return None

    # é˜¶æ®µ3: ç”¨æˆ·æ¨æ–­
    logger.info("=" * 60)
    logger.info("é˜¶æ®µ3: ç”¨æˆ·IDæ¨æ–­")
    logger.info("=" * 60)
    check_interrupt()

    stage3_start = time.time()
    user_inferrer = UserInferrer("config/user_inference_config.yaml")
    stage3_result = user_inferrer.infer_user_ids(stage2_output, f"{output_dir}/stage3_user_inference")
    stage3_time = time.time() - stage3_start
    logger.info(f"é˜¶æ®µ3å®Œæˆï¼Œè€—æ—¶: {format_time(stage3_time)}")

    # è·å–é˜¶æ®µ3çš„ä¸»è¦è¾“å‡ºæ–‡ä»¶
    stage3_output = stage3_result.get('complete_data', stage3_result.get('processed_data', ''))
    if not stage3_output:
        logger.error("âŒ é˜¶æ®µ3æœªäº§ç”Ÿæœ‰æ•ˆè¾“å‡ºæ–‡ä»¶")
        return None

    # é˜¶æ®µ4: ç¼ºå¤±æ•°æ®åˆ†æ (çº¯åˆ†æé˜¶æ®µï¼Œä¸ä¿®æ”¹ä¸»æ•°æ®æµ)
    logger.info("=" * 60)
    logger.info("é˜¶æ®µ4: ç¼ºå¤±æ•°æ®åˆ†æ")
    logger.info("=" * 60)
    check_interrupt()

    stage4_start = time.time()
    missing_analyzer = MissingAnalyzer("config/missing_analysis_config.yaml")
    stage4_reports = missing_analyzer.analyze_missing_data(stage3_output, f"{output_dir}/stage4_missing_analysis")
    stage4_time = time.time() - stage4_start
    logger.info(f"é˜¶æ®µ4å®Œæˆï¼Œè€—æ—¶: {format_time(stage4_time)}")

    # é˜¶æ®µ4åªç”Ÿæˆåˆ†ææŠ¥å‘Šï¼Œä¸»æ•°æ®æµç»§ç»­ä½¿ç”¨stage3_output
    logger.info(f"âœ… ç¼ºå¤±æ•°æ®åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {len(stage4_reports)} ä¸ªæ–‡ä»¶")
    logger.info(f"ğŸ“Š ä¸»æ•°æ®æµç»§ç»­ä½¿ç”¨: {stage3_output}")

    # é˜¶æ®µ5: æ™ºèƒ½é‡‡æ · (ä½¿ç”¨stage3_outputè€Œä¸æ˜¯stage4_output)
    logger.info("=" * 60)
    logger.info("é˜¶æ®µ5: æ™ºèƒ½é‡‡æ ·")
    logger.info("=" * 60)
    check_interrupt()

    stage5_start = time.time()
    intelligent_sampler = IntelligentSampler("config/intelligent_sampling_config.yaml")
    # ä¿®æ­£: ä½¿ç”¨stage3_outputä½œä¸ºè¾“å…¥ï¼Œè€Œä¸æ˜¯stage4_output
    stage5_result = intelligent_sampler.perform_intelligent_sampling(stage3_output, f"{output_dir}/stage5_intelligent_sampling")
    stage5_time = time.time() - stage5_start
    logger.info(f"é˜¶æ®µ5å®Œæˆï¼Œè€—æ—¶: {format_time(stage5_time)}")

    # è·å–é˜¶æ®µ5è¾“å‡ºæ–‡ä»¶
    stage5_output = stage5_result.get('sampled_data', stage5_result.get('final_data', ''))

    # é˜¶æ®µ6: æ•°æ®æ ‡å‡†åŒ–
    logger.info("=" * 60)
    logger.info("é˜¶æ®µ6: æ•°æ®æ ‡å‡†åŒ–")
    logger.info("=" * 60)
    check_interrupt()

    stage6_start = time.time()
    data_standardizer = DataStandardizer("config/generation_filter_config.yaml")
    stage6_result = data_standardizer.standardize_data(stage5_output, f"{output_dir}/stage6_data_standardization")
    stage6_time = time.time() - stage6_start
    logger.info(f"é˜¶æ®µ6å®Œæˆï¼Œè€—æ—¶: {format_time(stage6_time)}")

    # è·å–æœ€ç»ˆè¾“å‡ºæ–‡ä»¶
    final_output = stage6_result['standardized_data']
    return final_output

def main():
    """ä¸»å‡½æ•°"""
    # æ³¨å†Œä¿¡å·å¤„ç†å™¨
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)



    # é…ç½®å‚æ•° - ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼ˆåŸºäºå½“å‰è„šæœ¬ä½ç½®ï¼‰
    # å½“å‰è„šæœ¬åœ¨: Stage01_data_filter_preprocess/run_stable_processing.py
    # ç›®æ ‡æ–‡ä»¶åœ¨: Stage00_HPC_raw_data/jobinfo_20250224_113534.csv
    # éœ€è¦å‘ä¸Šä¸€çº§åˆ° 01_HPC_Researchï¼Œç„¶åè¿›å…¥ Stage00_HPC_raw_data
    script_dir = Path(__file__).parent  # Stage01_data_filter_preprocess/
    project_root = script_dir.parent     # 01_HPC_Research/
    input_file = str(project_root / "Stage00_HPC_raw_data" / "jobinfo_20250224_113534.csv")
    output_dir = "full_processing_outputs"
    
    logger.info("=" * 80)
    logger.info("ğŸš€ ç¨³å®šç‰ˆå…¨é‡æ•°æ®è¿‡æ»¤å’Œé¢„å¤„ç†ç³»ç»Ÿ")
    logger.info("=" * 80)
    logger.info("ä¼˜åŒ–å†…å®¹:")
    logger.info("  âœ… ä¿®å¤å­—ç¬¦ä¸²æ‹¼æ¥é”™è¯¯")
    logger.info("  âœ… ä¿®å¤tqdmå…¼å®¹æ€§é—®é¢˜")
    logger.info("  âœ… æ”¯æŒä¸­é—´æ–‡ä»¶ä¿å­˜å’Œæ–­ç‚¹ç»­ä¼ ")
    logger.info("  âœ… ä¼˜åŒ–è¿›ç¨‹ç®¡ç†å’Œä¿¡å·å¤„ç†")
    logger.info("  âœ… é¢„è®¡å¤„ç†æ—¶é—´: 2-3å°æ—¶ (vs åŸæ¥çš„26å°æ—¶)")
    logger.info("=" * 80)
    logger.info(f"è¾“å…¥æ–‡ä»¶: {input_file}")
    logger.info(f"è¾“å‡ºç›®å½•: {output_dir}")
    logger.info(f"æ—¥å¿—æ–‡ä»¶: {log_filename}")
    logger.info(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(input_file):
        logger.error(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        sys.exit(1)
    
    # ä¼°ç®—å¤„ç†æ—¶é—´
    try:
        input_records, estimated_time, estimated_output = estimate_processing_time(input_file)
        logger.info("=" * 60)
        logger.info("ğŸ“Š å¤„ç†é¢„ä¼°")
        logger.info("=" * 60)
        logger.info(f"è¾“å…¥è®°å½•æ•°: {input_records:,} æ¡")
        logger.info(f"é¢„è®¡è¾“å‡ºè®°å½•æ•°: {estimated_output:,} æ¡")
        logger.info(f"é¢„è®¡å¤„ç†æ—¶é—´: {format_time(estimated_time)}")
    except Exception as e:
        logger.error(f"æ–‡ä»¶åˆ†æå¤±è´¥: {e}")
        sys.exit(1)
    
    # æ£€æŸ¥ä¸­é—´æ–‡ä»¶å¹¶ç¡®å®šå¼€å§‹é˜¶æ®µ
    logger.info("=" * 60)
    logger.info("ğŸ“‹ æ£€æŸ¥ä¸­é—´æ–‡ä»¶çŠ¶æ€")
    logger.info("=" * 60)
    existing_files = check_intermediate_files()
    start_stage = determine_start_stage(existing_files)

    # å¼€å§‹å¤„ç†
    start_time = time.time()

    try:
        if start_stage == 6:
            # æ‰€æœ‰é˜¶æ®µéƒ½å·²å®Œæˆ
            logger.info("ğŸ‰ æ‰€æœ‰å¤„ç†é˜¶æ®µéƒ½å·²å®Œæˆï¼Œæ— éœ€é‡æ–°å¤„ç†ï¼")
            final_output = existing_files["æœ€ç»ˆé‡‡æ ·ç»“æœ"]["path"]
        else:
            # æ ¹æ®å¼€å§‹é˜¶æ®µæ‰§è¡Œç›¸åº”çš„å¤„ç†
            final_output = run_stages_from(start_stage, input_file, output_dir, existing_files)

        # å¤„ç†å®Œæˆ
        end_time = time.time()
        total_duration = end_time - start_time

        logger.info("=" * 80)
        logger.info("ğŸ‰ ç¨³å®šç‰ˆå¤„ç†å®Œæˆ!")
        logger.info("=" * 80)
        logger.info(f"æ€»å¤„ç†æ—¶é—´: {format_time(total_duration)}")
        if total_duration > 0:
            logger.info(f"å®é™…å¤„ç†é€Ÿåº¦: {int(8376397 / total_duration)} æ¡è®°å½•/ç§’")
        logger.info(f"å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info(f"æœ€ç»ˆè¾“å‡º: {final_output}")
        logger.info(f"æ—¥å¿—æ–‡ä»¶: {log_filename}")
            
    except KeyboardInterrupt:
        logger.warning("âš ï¸  ç”¨æˆ·ä¸­æ–­å¤„ç†")
        sys.exit(1)
    except Exception as e:
        import traceback
        logger.error(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")
        logger.error("è¯¦ç»†é”™è¯¯å †æ ˆ:")
        logger.error(traceback.format_exc())
        sys.exit(1)

if __name__ == "__main__":
    main()
